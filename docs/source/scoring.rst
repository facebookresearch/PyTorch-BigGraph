From entity embeddings to relation scores
=========================================

The goal of training is to embed each entity in :math:`\mathbb{R}^D` so that
the embeddings of two entities are a good proxy to predict whether there is
a relation of a certain type between them.

To be more precise, the goal is to learn an embedding for each entity and a
function for each relation type that takes two entity embeddings and assigns
them a score, with the goal of having positive relations achieve higher scores
than negative ones.

All the edges provided in the training set are considered positive instances.
In order to perform training, a set of negative edges is needed as well. These
are not provided by the user but instead generated by the system during training
(see :ref:`negative-sampling`), usually by fixing the left-hand side entity and
the relation type and sampling a new right-hand side entity, or vice versa. This
sampling scheme makes sense for large sparse graphs, where there is a low
probability that edges generated this way are true positives edges in the graph.

A priori, entity embeddings could take any value in :math:`\mathbb{R}^D`. Although,
in some cases (for example when restricting them to be within a certain ball, or
when comparing them using cosine distance), their "angle" will have greater
importance than their norm.

Per-relation scoring functions, however, must be expressible in a specific form
(the most common functions in the literature can be converted to such a representation).
In the current implementation, they are only allowed to transform the embedding
of one of the two sides, which is then compared to the un-transformed embedding
of the other side using a generic symmetric metric function, which is the same
for all relations. Formally, for left- and right-hand side entities :math:`x`
and :math:`y` respectively, and for a relation type :math:`r`, the score is:

.. math::
    f_r(\theta_x, \theta_y) = m(\theta_x, g_r(\theta_y))

where :math:`\theta_x` and :math:`\theta_y` are the embeddings of :math:`x` and
:math:`y` respectively, :math:`f_r` is the scoring function for :math:`r`,
:math:`g_r` is the **operator** for :math:`r` and :math:`m` is the **metric**.

.. note::
    The operator being applied to the right-hand side embedding is just an example
    and, while it's what happens when using standard operators, it's not always
    the case for :ref:`dynamic relations <dynamic-relations>`.

Embeddings
----------

Embeddings live in a :math:`D`-dimensional real space, where :math:`D` is
determined by the ``dimension`` configuration parameter.

Normally, each entity has its own embedding, which is entirely independent from
any other entity's embedding. When using :ref:`featurized entities <featurized-entities>`
however this works differently, and an entity's embedding will be the average of
the embeddings of its features.

.. todo:: mention max norm

To add a new type of embedding, one needs to subclass the :class:`torchbiggraph.model.AbstractEmbedding` class.

Global embeddings
-----------------

When the ``globalEmb`` configuration option is active, each entity's embedding
will be translated by a vector that is specific to each entity type (and that is
learned at the same time as the embeddings).

Operators
---------

The operators that are currently provided are:

* ``none``, no-op, which leaves the embeddings unchanged;
* ``translation``, which adds to the embedding a vector of the same dimension;
* ``diagonal``, multiplication of each dimension by a different coefficient
  (equivalent to multiplying by a diagonal matrix);
* ``affine_rhs``, affine transformation, i.e., multiplication by a full square
  matrix plus addition of a vector.

All the operators' parameters are learned during training.

To define an additional operator, one must subclass the :class:`torchbiggraph.model.AbstractOperator` class
(or the :class:`torchbiggraph.model.AbstractDynamicOperator` one when using :ref:`dynamic relations <dynamic-relations>`)
and add an entry to the :class:`torchbiggraph.config.Operator` enum.

Metrics
-------

.. note::
    "Metric" is a misnomer, as these binary operators act as comparators that
    give *higher* scores for arguments that are "closer", and are allowed to
    produce negative values (contrary to metrics, that must return non-negative
    values, with smaller ones meaning the operands are more similar).

The available metrics are:

* ``dot``, the dot-product, which computes the scalar or inner product of the two
  embedding vectors;
* ``cos``, the cos distance, which is the cosine of the angle between the two vectors
  or, equivalently, the dot product divided by the product of the vectors' norms.

Custom metrics need to extend the :class:`torchbiggraph.model.AbstractMetric` class
and add an item to the :class:`torchbiggraph.config.Metric` enum.

Bias
----

If the ``bias`` configuration key is in use, then the first coordinate of the
embeddings will act as a bias in the metric computation. This means that the
metric will be computed on the last :math:`D - 1` entries of the vectors only,
and then both the first entries of the two vectors will be added to the result.

Coherent sets of configuration parameters
-----------------------------------------

While the parameters described in this chapter are exposed as uncoupled knobs
in the configuration file (to more closely match the implementation, and to allow
for more flexible tuning), some combinations of them are more sensible than others.

Apart from the default one, the following configuration has been found to work well:
``initScale`` = 0.1, ``metric`` = ``dot``, ``bias`` = true, ``lossFn`` = ``logistic``, ``lr`` = 0.1.

Interpreting the scores
-----------------------

The scores will be tuned to have different meaning and become more suitable for
certain applications based on the :ref:`loss function <loss-calculation>` used during training.
Common options include ranking what other entities may be related to a given entity,
determining the probability that a certain relation exists between two given
entities, etc.

.. todo::
    Talk about what you can *do* with the trained embeddings (e.g., compute P(edge),
    k-nearest-neighbors, or training downstream classifiers on the features).
    Also, it would be nice to have a little script where one could manually feed
    it an edge and it could spit out a score. Or some nearest neighbor tool.
